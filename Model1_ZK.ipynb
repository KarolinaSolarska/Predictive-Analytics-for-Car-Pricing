{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 - Z.K."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/cleaned_data.csv.gz\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_production</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine_capacity</th>\n",
       "      <th>power</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>price</th>\n",
       "      <th>Abarth</th>\n",
       "      <th>Acura</th>\n",
       "      <th>Aixam</th>\n",
       "      <th>Alfa Romeo</th>\n",
       "      <th>...</th>\n",
       "      <th>Navy_blue</th>\n",
       "      <th>Orange</th>\n",
       "      <th>Other_color</th>\n",
       "      <th>Purple</th>\n",
       "      <th>Red</th>\n",
       "      <th>Silver</th>\n",
       "      <th>White</th>\n",
       "      <th>Yellow</th>\n",
       "      <th>New_cars</th>\n",
       "      <th>Used_cars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>48000</td>\n",
       "      <td>1368</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>82999</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>54500</td>\n",
       "      <td>1368</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>59900</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>5578</td>\n",
       "      <td>1368</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>135000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>116000</td>\n",
       "      <td>1368</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>79900</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>31190</td>\n",
       "      <td>1368</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>82000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184247</th>\n",
       "      <td>2017</td>\n",
       "      <td>85000</td>\n",
       "      <td>1499</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>39900</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184248</th>\n",
       "      <td>2015</td>\n",
       "      <td>122300</td>\n",
       "      <td>1998</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>68000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184249</th>\n",
       "      <td>2019</td>\n",
       "      <td>97711</td>\n",
       "      <td>2488</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>119900</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184250</th>\n",
       "      <td>2015</td>\n",
       "      <td>189300</td>\n",
       "      <td>2191</td>\n",
       "      <td>175</td>\n",
       "      <td>1</td>\n",
       "      <td>65500</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184251</th>\n",
       "      <td>2020</td>\n",
       "      <td>59973</td>\n",
       "      <td>2488</td>\n",
       "      <td>194</td>\n",
       "      <td>1</td>\n",
       "      <td>99800</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184252 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year_production  mileage  engine_capacity  power  gearbox   price  \\\n",
       "0                  2018    48000             1368    145        0   82999   \n",
       "1                  2016    54500             1368    145        0   59900   \n",
       "2                  2023     5578             1368    165        1  135000   \n",
       "3                  2019   116000             1368    165        0   79900   \n",
       "4                  2022    31190             1368    145        0   82000   \n",
       "...                 ...      ...              ...    ...      ...     ...   \n",
       "184247             2017    85000             1499    105        0   39900   \n",
       "184248             2015   122300             1998    165        0   68000   \n",
       "184249             2019    97711             2488    194        1  119900   \n",
       "184250             2015   189300             2191    175        1   65500   \n",
       "184251             2020    59973             2488    194        1   99800   \n",
       "\n",
       "        Abarth  Acura  Aixam  Alfa Romeo  ...  Navy_blue  Orange  Other_color  \\\n",
       "0         True  False  False       False  ...      False   False        False   \n",
       "1         True  False  False       False  ...      False   False        False   \n",
       "2         True  False  False       False  ...      False   False        False   \n",
       "3         True  False  False       False  ...      False   False        False   \n",
       "4         True  False  False       False  ...      False   False        False   \n",
       "...        ...    ...    ...         ...  ...        ...     ...          ...   \n",
       "184247   False  False  False       False  ...      False   False        False   \n",
       "184248   False  False  False       False  ...      False   False        False   \n",
       "184249   False  False  False       False  ...      False   False        False   \n",
       "184250   False  False  False       False  ...      False   False        False   \n",
       "184251   False  False  False       False  ...      False   False        False   \n",
       "\n",
       "        Purple    Red  Silver  White  Yellow  New_cars  Used_cars  \n",
       "0        False  False   False   True   False     False       True  \n",
       "1        False   True   False  False   False     False       True  \n",
       "2        False  False   False  False   False     False       True  \n",
       "3        False  False   False  False   False     False       True  \n",
       "4        False   True   False  False   False     False       True  \n",
       "...        ...    ...     ...    ...     ...       ...        ...  \n",
       "184247   False  False   False  False   False     False       True  \n",
       "184248   False  False   False  False   False     False       True  \n",
       "184249   False  False   False   True   False     False       True  \n",
       "184250   False   True   False  False   False     False       True  \n",
       "184251   False  False   False  False   False     False       True  \n",
       "\n",
       "[184252 rows x 150 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target variable - \"price\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: ['year_production', 'mileage', 'engine_capacity', 'power', 'gearbox']\n",
      "Categorical columns: ['Abarth', 'Acura', 'Aixam', 'Alfa Romeo', 'Alpine', 'Aston Martin', 'Audi', 'Austin', 'BMW', 'BMW-ALPINA', 'BYD', 'Baic', 'Bentley', 'Brilliance', 'Buick', 'Cadillac', 'Casalini', 'Chatenet', 'Chevrolet', 'Chrysler', 'Citroën', 'Cupra', 'DFSK', 'DKW', 'DS Automobiles', 'Dacia', 'Daewoo', 'Daihatsu', 'Dodge', 'Ferrari', 'Fiat', 'Ford', 'GMC', 'Gaz', 'Honda', 'Hummer', 'Hyundai', 'Ineos', 'Infiniti', 'Inny', 'Isuzu', 'Iveco', 'Jaguar', 'Jeep', 'Jetour', 'Kia', 'Lada', 'Lamborghini', 'Lancia', 'Land Rover', 'Lexus', 'Ligier', 'Lincoln', 'Lotus', 'MAN', 'MG', 'MINI', 'Maserati', 'Maybach', 'Mazda', 'McLaren', 'Mercedes-Benz', 'Mercury', 'Microcar', 'Mitsubishi', 'Nissan', 'Nysa', 'Oldsmobile', 'Omoda', 'Opel', 'Peugeot', 'Plymouth', 'Polonez', 'Pontiac', 'Porsche', 'RAM', 'Renault', 'Rolls-Royce', 'Rover', 'Saab', 'Seat', 'Skoda', 'Skywell', 'Smart', 'SsangYong', 'Subaru', 'Suzuki', 'Syrena', 'Tarpan', 'Tata', 'Tesla', 'Toyota', 'Trabant', 'Triumph', 'Uaz', 'VELEX', 'Volkswagen', 'Volvo', 'Warszawa', 'Wartburg', 'Wołga', 'e.GO', 'Żuk', 'Benzyna', 'Benzyna+LPG', 'Diesel', 'Hybryda', 'Hybryda Plug-in', '4x4', 'Front_wheel_drive', 'Rear_wheel_drive', 'Cabriolet', 'City_cars', 'Combi', 'Compact', 'Coupe', 'Minivan', 'SUV', 'Sedan', 'Small_cars', 'doors_2', 'doors_3', 'doors_4', 'doors_5', 'doors_6', 'Beige', 'Black', 'Blue', 'Brown', 'Burgundy', 'Gold', 'Gray', 'Green', 'Light_blue', 'Navy_blue', 'Orange', 'Other_color', 'Purple', 'Red', 'Silver', 'White', 'Yellow', 'New_cars', 'Used_cars']\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
    "numeric_cols.remove('price')\n",
    "categorical_cols = df.select_dtypes(exclude=['number']).columns.tolist()\n",
    "\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = df.select_dtypes(exclude=['number']).columns.tolist()\n",
    "\n",
    "df = pd.concat([df[numeric_cols + ['price']], df[categorical_cols]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_production</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine_capacity</th>\n",
       "      <th>power</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>price</th>\n",
       "      <th>Abarth</th>\n",
       "      <th>Acura</th>\n",
       "      <th>Aixam</th>\n",
       "      <th>Alfa Romeo</th>\n",
       "      <th>...</th>\n",
       "      <th>Navy_blue</th>\n",
       "      <th>Orange</th>\n",
       "      <th>Other_color</th>\n",
       "      <th>Purple</th>\n",
       "      <th>Red</th>\n",
       "      <th>Silver</th>\n",
       "      <th>White</th>\n",
       "      <th>Yellow</th>\n",
       "      <th>New_cars</th>\n",
       "      <th>Used_cars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.480689</td>\n",
       "      <td>-0.968906</td>\n",
       "      <td>-0.699431</td>\n",
       "      <td>-0.254407</td>\n",
       "      <td>-0.944106</td>\n",
       "      <td>82999</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.161685</td>\n",
       "      <td>-0.899704</td>\n",
       "      <td>-0.699431</td>\n",
       "      <td>-0.254407</td>\n",
       "      <td>-0.944106</td>\n",
       "      <td>59900</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.278200</td>\n",
       "      <td>-1.420546</td>\n",
       "      <td>-0.699431</td>\n",
       "      <td>-0.016959</td>\n",
       "      <td>1.059204</td>\n",
       "      <td>135000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.640191</td>\n",
       "      <td>-0.244952</td>\n",
       "      <td>-0.699431</td>\n",
       "      <td>-0.016959</td>\n",
       "      <td>-0.944106</td>\n",
       "      <td>79900</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.118698</td>\n",
       "      <td>-1.147871</td>\n",
       "      <td>-0.699431</td>\n",
       "      <td>-0.254407</td>\n",
       "      <td>-0.944106</td>\n",
       "      <td>82000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year_production   mileage  engine_capacity     power   gearbox   price  \\\n",
       "0         0.480689 -0.968906        -0.699431 -0.254407 -0.944106   82999   \n",
       "1         0.161685 -0.899704        -0.699431 -0.254407 -0.944106   59900   \n",
       "2         1.278200 -1.420546        -0.699431 -0.016959  1.059204  135000   \n",
       "3         0.640191 -0.244952        -0.699431 -0.016959 -0.944106   79900   \n",
       "4         1.118698 -1.147871        -0.699431 -0.254407 -0.944106   82000   \n",
       "\n",
       "   Abarth  Acura  Aixam  Alfa Romeo  ...  Navy_blue  Orange  Other_color  \\\n",
       "0       1      0      0           0  ...          0       0            0   \n",
       "1       1      0      0           0  ...          0       0            0   \n",
       "2       1      0      0           0  ...          0       0            0   \n",
       "3       1      0      0           0  ...          0       0            0   \n",
       "4       1      0      0           0  ...          0       0            0   \n",
       "\n",
       "   Purple  Red  Silver  White  Yellow  New_cars  Used_cars  \n",
       "0       0    0       0      1       0         0          1  \n",
       "1       0    1       0      0       0         0          1  \n",
       "2       0    0       0      0       0         0          1  \n",
       "3       0    0       0      0       0         0          1  \n",
       "4       0    1       0      0       0         0          1  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df*1\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_production</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine_capacity</th>\n",
       "      <th>power</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>price</th>\n",
       "      <th>Abarth</th>\n",
       "      <th>Acura</th>\n",
       "      <th>Aixam</th>\n",
       "      <th>Alfa Romeo</th>\n",
       "      <th>...</th>\n",
       "      <th>Navy_blue</th>\n",
       "      <th>Orange</th>\n",
       "      <th>Other_color</th>\n",
       "      <th>Purple</th>\n",
       "      <th>Red</th>\n",
       "      <th>Silver</th>\n",
       "      <th>White</th>\n",
       "      <th>Yellow</th>\n",
       "      <th>New_cars</th>\n",
       "      <th>Used_cars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.842520e+05</td>\n",
       "      <td>1.842520e+05</td>\n",
       "      <td>1.842520e+05</td>\n",
       "      <td>1.842520e+05</td>\n",
       "      <td>1.842520e+05</td>\n",
       "      <td>1.842520e+05</td>\n",
       "      <td>184252.000000</td>\n",
       "      <td>184252.000000</td>\n",
       "      <td>184252.000000</td>\n",
       "      <td>184252.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>184252.000000</td>\n",
       "      <td>184252.000000</td>\n",
       "      <td>184252.000000</td>\n",
       "      <td>184252.000000</td>\n",
       "      <td>184252.000000</td>\n",
       "      <td>184252.000000</td>\n",
       "      <td>184252.000000</td>\n",
       "      <td>184252.000000</td>\n",
       "      <td>184252.000000</td>\n",
       "      <td>184252.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.299731e-15</td>\n",
       "      <td>1.987353e-16</td>\n",
       "      <td>-3.906991e-14</td>\n",
       "      <td>-3.410864e-15</td>\n",
       "      <td>-1.593782e-13</td>\n",
       "      <td>8.243270e+04</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.008803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033069</td>\n",
       "      <td>0.005829</td>\n",
       "      <td>0.045210</td>\n",
       "      <td>0.003387</td>\n",
       "      <td>0.048016</td>\n",
       "      <td>0.109730</td>\n",
       "      <td>0.168335</td>\n",
       "      <td>0.004005</td>\n",
       "      <td>0.085584</td>\n",
       "      <td>0.914416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.004107e+05</td>\n",
       "      <td>0.018192</td>\n",
       "      <td>0.009318</td>\n",
       "      <td>0.018779</td>\n",
       "      <td>0.093412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178817</td>\n",
       "      <td>0.076125</td>\n",
       "      <td>0.207765</td>\n",
       "      <td>0.058097</td>\n",
       "      <td>0.213800</td>\n",
       "      <td>0.312554</td>\n",
       "      <td>0.374164</td>\n",
       "      <td>0.063161</td>\n",
       "      <td>0.279749</td>\n",
       "      <td>0.279749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.594802e+01</td>\n",
       "      <td>-1.479921e+00</td>\n",
       "      <td>-1.939297e+00</td>\n",
       "      <td>-1.916545e+00</td>\n",
       "      <td>-9.441056e-01</td>\n",
       "      <td>5.550000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.358250e-01</td>\n",
       "      <td>-8.101068e-01</td>\n",
       "      <td>-5.329200e-01</td>\n",
       "      <td>-6.105798e-01</td>\n",
       "      <td>-9.441056e-01</td>\n",
       "      <td>2.700000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.616853e-01</td>\n",
       "      <td>4.572750e-03</td>\n",
       "      <td>-2.314017e-02</td>\n",
       "      <td>-1.950454e-01</td>\n",
       "      <td>-9.441056e-01</td>\n",
       "      <td>5.300000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.401915e-01</td>\n",
       "      <td>6.812832e-01</td>\n",
       "      <td>1.062261e-01</td>\n",
       "      <td>2.798512e-01</td>\n",
       "      <td>1.059204e+00</td>\n",
       "      <td>9.999900e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.437702e+00</td>\n",
       "      <td>6.960102e+00</td>\n",
       "      <td>8.307533e+00</td>\n",
       "      <td>1.583271e+01</td>\n",
       "      <td>1.059204e+00</td>\n",
       "      <td>3.700000e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year_production       mileage  engine_capacity         power  \\\n",
       "count     1.842520e+05  1.842520e+05     1.842520e+05  1.842520e+05   \n",
       "mean     -1.299731e-15  1.987353e-16    -3.906991e-14 -3.410864e-15   \n",
       "std       1.000003e+00  1.000003e+00     1.000003e+00  1.000003e+00   \n",
       "min      -1.594802e+01 -1.479921e+00    -1.939297e+00 -1.916545e+00   \n",
       "25%      -6.358250e-01 -8.101068e-01    -5.329200e-01 -6.105798e-01   \n",
       "50%       1.616853e-01  4.572750e-03    -2.314017e-02 -1.950454e-01   \n",
       "75%       6.401915e-01  6.812832e-01     1.062261e-01  2.798512e-01   \n",
       "max       1.437702e+00  6.960102e+00     8.307533e+00  1.583271e+01   \n",
       "\n",
       "            gearbox         price         Abarth          Acura  \\\n",
       "count  1.842520e+05  1.842520e+05  184252.000000  184252.000000   \n",
       "mean  -1.593782e-13  8.243270e+04       0.000331       0.000087   \n",
       "std    1.000003e+00  1.004107e+05       0.018192       0.009318   \n",
       "min   -9.441056e-01  5.550000e+02       0.000000       0.000000   \n",
       "25%   -9.441056e-01  2.700000e+04       0.000000       0.000000   \n",
       "50%   -9.441056e-01  5.300000e+04       0.000000       0.000000   \n",
       "75%    1.059204e+00  9.999900e+04       0.000000       0.000000   \n",
       "max    1.059204e+00  3.700000e+06       1.000000       1.000000   \n",
       "\n",
       "               Aixam     Alfa Romeo  ...      Navy_blue         Orange  \\\n",
       "count  184252.000000  184252.000000  ...  184252.000000  184252.000000   \n",
       "mean        0.000353       0.008803  ...       0.033069       0.005829   \n",
       "std         0.018779       0.093412  ...       0.178817       0.076125   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "50%         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "75%         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "max         1.000000       1.000000  ...       1.000000       1.000000   \n",
       "\n",
       "         Other_color         Purple            Red         Silver  \\\n",
       "count  184252.000000  184252.000000  184252.000000  184252.000000   \n",
       "mean        0.045210       0.003387       0.048016       0.109730   \n",
       "std         0.207765       0.058097       0.213800       0.312554   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "               White         Yellow       New_cars      Used_cars  \n",
       "count  184252.000000  184252.000000  184252.000000  184252.000000  \n",
       "mean        0.168335       0.004005       0.085584       0.914416  \n",
       "std         0.374164       0.063161       0.279749       0.279749  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000       1.000000  \n",
       "50%         0.000000       0.000000       0.000000       1.000000  \n",
       "75%         0.000000       0.000000       0.000000       1.000000  \n",
       "max         1.000000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 150 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lasso regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Estimate lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha using built-in LassoCV:  65.02589543828756\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# Set up the LassoCV regressor\n",
    "lasso_cv = LassoCV(cv=5, random_state=42, max_iter=10000)\n",
    "\n",
    "# Fit the model on the training data\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the best alpha found\n",
    "print(\"Best alpha using built-in LassoCV: \", lasso_cv.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best alpha using built-in LassoCV:  65.02589543828756"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 2782834729.7345786\n",
      "Test MSE: 2926085206.831737\n",
      "Train R²: 0.7243004177761863\n",
      "Test R²: 0.7089960470467618\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Predict on training and test data\n",
    "y_train_pred = lasso_cv.predict(X_train)\n",
    "y_test_pred = lasso_cv.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Train MSE:\", train_mse)\n",
    "print(\"Test MSE:\", test_mse)\n",
    "print(\"Train R²:\", train_r2)\n",
    "print(\"Test R²:\", test_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We give up lasso for this script in aim of training xgb. Built-in lasso performance is not sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Total sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Estimate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBR = xgb.XGBRegressor(n_estimators=1000, max_depth=7, eta=0.1, subsample=0.7, colsample_bytree=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [700, 800, 900, 1000, 1100, 1200],  # Number of trees\n",
    "    'max_depth': [6, 7, 8, 9, 10, 11, 12, 13, 14, 15],  # Maximum depth of trees\n",
    "    'learning_rate': [0.01, 0.05, 0.08, 0.1, 0.15, 0.2],  # Learning rate\n",
    "    'subsample': [0.6, 0.65, 0.7, 0.75, 0.8, 0.85],  # Fraction of samples used for tree building\n",
    "    'colsample_bytree': [0.7, 0.75, 0.8, 0.85, 0.9],  # Fraction of features used for tree building\n",
    "    'min_child_weight': [2, 3, 4],  # Minimum sum of instance weight needed in a child\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    estimator = XGBR,\n",
    "    param_distributions=param_grid,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_iter=50,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.85, learning_rate=0.1, max_depth=15, min_child_weight=2, n_estimators=700, subsample=0.7; total time=  53.9s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.1, max_depth=15, min_child_weight=2, n_estimators=700, subsample=0.7; total time=  54.9s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.1, max_depth=15, min_child_weight=2, n_estimators=700, subsample=0.7; total time=  54.9s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.1, max_depth=15, min_child_weight=2, n_estimators=700, subsample=0.7; total time=  56.1s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.1, max_depth=15, min_child_weight=2, n_estimators=700, subsample=0.7; total time=  56.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.08, max_depth=12, min_child_weight=2, n_estimators=1100, subsample=0.75; total time=  58.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.08, max_depth=12, min_child_weight=2, n_estimators=1100, subsample=0.75; total time=  58.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.08, max_depth=12, min_child_weight=2, n_estimators=1100, subsample=0.75; total time= 1.0min\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.08, max_depth=12, min_child_weight=2, n_estimators=1100, subsample=0.75; total time= 1.1min\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.08, max_depth=12, min_child_weight=2, n_estimators=1100, subsample=0.75; total time= 1.1min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=13, min_child_weight=4, n_estimators=1200, subsample=0.7; total time= 1.2min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=13, min_child_weight=4, n_estimators=1200, subsample=0.7; total time= 1.2min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=13, min_child_weight=4, n_estimators=1200, subsample=0.7; total time= 1.2min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=13, min_child_weight=4, n_estimators=1200, subsample=0.7; total time= 1.2min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=13, min_child_weight=4, n_estimators=1200, subsample=0.7; total time= 1.2min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=15, min_child_weight=4, n_estimators=1100, subsample=0.7; total time= 1.5min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=11, min_child_weight=4, n_estimators=1200, subsample=0.6; total time= 1.0min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=11, min_child_weight=4, n_estimators=1200, subsample=0.6; total time= 1.0min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=11, min_child_weight=4, n_estimators=1200, subsample=0.6; total time= 1.0min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=15, min_child_weight=4, n_estimators=1100, subsample=0.7; total time= 1.5min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=15, min_child_weight=4, n_estimators=1100, subsample=0.7; total time= 1.4min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=11, min_child_weight=4, n_estimators=1200, subsample=0.6; total time= 1.0min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=15, min_child_weight=4, n_estimators=1100, subsample=0.7; total time= 1.4min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=15, min_child_weight=4, n_estimators=1100, subsample=0.7; total time= 1.4min\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=6, min_child_weight=4, n_estimators=900, subsample=0.6; total time=  29.4s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=6, min_child_weight=4, n_estimators=900, subsample=0.6; total time=  29.0s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.05, max_depth=15, min_child_weight=4, n_estimators=800, subsample=0.85; total time=  57.7s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.05, max_depth=15, min_child_weight=4, n_estimators=800, subsample=0.85; total time=  58.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=11, min_child_weight=4, n_estimators=1200, subsample=0.6; total time= 1.0min\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.05, max_depth=15, min_child_weight=4, n_estimators=800, subsample=0.85; total time=  57.1s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.05, max_depth=15, min_child_weight=4, n_estimators=800, subsample=0.85; total time=  57.8s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.05, max_depth=15, min_child_weight=4, n_estimators=800, subsample=0.85; total time=  57.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=6, min_child_weight=4, n_estimators=900, subsample=0.6; total time=  29.1s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=6, min_child_weight=4, n_estimators=900, subsample=0.6; total time=  28.3s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.2, max_depth=6, min_child_weight=4, n_estimators=900, subsample=0.6; total time=  28.5s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.15, max_depth=10, min_child_weight=3, n_estimators=900, subsample=0.8; total time=  45.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.15, max_depth=10, min_child_weight=3, n_estimators=900, subsample=0.8; total time=  45.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.15, max_depth=10, min_child_weight=3, n_estimators=900, subsample=0.8; total time=  43.8s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.15, max_depth=10, min_child_weight=3, n_estimators=900, subsample=0.8; total time=  45.2s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.08, max_depth=10, min_child_weight=4, n_estimators=900, subsample=0.7; total time=  40.3s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.08, max_depth=10, min_child_weight=4, n_estimators=900, subsample=0.7; total time=  41.0s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.15, max_depth=10, min_child_weight=3, n_estimators=900, subsample=0.8; total time=  44.0s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.08, max_depth=10, min_child_weight=4, n_estimators=900, subsample=0.7; total time=  40.0s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.08, max_depth=10, min_child_weight=4, n_estimators=900, subsample=0.7; total time=  40.0s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.08, max_depth=10, min_child_weight=4, n_estimators=900, subsample=0.7; total time=  42.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=12, min_child_weight=2, n_estimators=700, subsample=0.7; total time=  47.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=14, min_child_weight=2, n_estimators=700, subsample=0.65; total time= 1.0min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=14, min_child_weight=2, n_estimators=700, subsample=0.65; total time=  59.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=14, min_child_weight=2, n_estimators=700, subsample=0.65; total time=  58.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=14, min_child_weight=2, n_estimators=700, subsample=0.65; total time=  58.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=14, min_child_weight=2, n_estimators=700, subsample=0.65; total time=  58.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=12, min_child_weight=2, n_estimators=700, subsample=0.7; total time=  46.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=12, min_child_weight=2, n_estimators=700, subsample=0.7; total time=  45.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=12, min_child_weight=2, n_estimators=700, subsample=0.7; total time=  46.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=12, min_child_weight=2, n_estimators=700, subsample=0.7; total time=  45.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=6, min_child_weight=4, n_estimators=1200, subsample=0.8; total time=  39.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=12, min_child_weight=4, n_estimators=1200, subsample=0.6; total time= 1.2min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=12, min_child_weight=4, n_estimators=1200, subsample=0.6; total time= 1.2min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=12, min_child_weight=4, n_estimators=1200, subsample=0.6; total time= 1.2min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=12, min_child_weight=4, n_estimators=1200, subsample=0.6; total time= 1.2min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=6, min_child_weight=4, n_estimators=1200, subsample=0.8; total time=  38.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=12, min_child_weight=4, n_estimators=1200, subsample=0.6; total time= 1.2min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=6, min_child_weight=4, n_estimators=1200, subsample=0.8; total time=  38.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=6, min_child_weight=4, n_estimators=1200, subsample=0.8; total time=  39.5s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.08, max_depth=9, min_child_weight=3, n_estimators=700, subsample=0.7; total time=  31.1s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.08, max_depth=9, min_child_weight=3, n_estimators=700, subsample=0.7; total time=  30.5s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.08, max_depth=9, min_child_weight=3, n_estimators=700, subsample=0.7; total time=  30.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=6, min_child_weight=4, n_estimators=1200, subsample=0.8; total time=  38.0s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.08, max_depth=9, min_child_weight=3, n_estimators=700, subsample=0.7; total time=  30.3s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.08, max_depth=9, min_child_weight=3, n_estimators=700, subsample=0.7; total time=  29.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=9, min_child_weight=3, n_estimators=1000, subsample=0.85; total time=  42.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=9, min_child_weight=3, n_estimators=1000, subsample=0.85; total time=  41.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=9, min_child_weight=3, n_estimators=1000, subsample=0.85; total time=  40.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=9, min_child_weight=3, n_estimators=1000, subsample=0.85; total time=  41.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=9, min_child_weight=3, n_estimators=1000, subsample=0.85; total time=  42.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=15, min_child_weight=3, n_estimators=900, subsample=0.6; total time= 1.2min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=15, min_child_weight=3, n_estimators=900, subsample=0.6; total time= 1.2min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=15, min_child_weight=3, n_estimators=900, subsample=0.6; total time= 1.2min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=15, min_child_weight=3, n_estimators=900, subsample=0.6; total time= 1.2min\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.15, max_depth=11, min_child_weight=2, n_estimators=1000, subsample=0.85; total time=  58.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=15, min_child_weight=3, n_estimators=900, subsample=0.6; total time= 1.2min\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.15, max_depth=11, min_child_weight=2, n_estimators=1000, subsample=0.85; total time= 1.0min\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.15, max_depth=11, min_child_weight=2, n_estimators=1000, subsample=0.85; total time= 1.0min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=10, min_child_weight=3, n_estimators=1100, subsample=0.75; total time=  52.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.15, max_depth=11, min_child_weight=2, n_estimators=1000, subsample=0.85; total time= 1.0min\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.15, max_depth=11, min_child_weight=2, n_estimators=1000, subsample=0.85; total time= 1.0min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=10, min_child_weight=3, n_estimators=1100, subsample=0.75; total time= 2.1min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=10, min_child_weight=3, n_estimators=1100, subsample=0.75; total time= 2.1min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=10, min_child_weight=3, n_estimators=1100, subsample=0.75; total time= 2.1min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=10, min_child_weight=3, n_estimators=1100, subsample=0.75; total time= 2.1min\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.08, max_depth=14, min_child_weight=3, n_estimators=700, subsample=0.75; total time= 2.2min\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.08, max_depth=14, min_child_weight=3, n_estimators=700, subsample=0.75; total time= 2.1min\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.08, max_depth=14, min_child_weight=3, n_estimators=700, subsample=0.75; total time= 2.0min\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.08, max_depth=14, min_child_weight=3, n_estimators=700, subsample=0.75; total time= 2.0min\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.08, max_depth=14, min_child_weight=3, n_estimators=700, subsample=0.75; total time=16.9min\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=13, min_child_weight=2, n_estimators=800, subsample=0.6; total time=16.9min\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=13, min_child_weight=2, n_estimators=800, subsample=0.6; total time=16.9min\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=13, min_child_weight=2, n_estimators=800, subsample=0.6; total time=16.9min\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=13, min_child_weight=2, n_estimators=800, subsample=0.6; total time=16.9min\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.05, max_depth=13, min_child_weight=2, n_estimators=800, subsample=0.6; total time=32.5min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=11, min_child_weight=3, n_estimators=1100, subsample=0.85; total time=32.5min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=11, min_child_weight=3, n_estimators=1100, subsample=0.85; total time=32.5min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=11, min_child_weight=3, n_estimators=1100, subsample=0.85; total time=16.4min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=11, min_child_weight=3, n_estimators=1100, subsample=0.85; total time=16.3min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=11, min_child_weight=3, n_estimators=1100, subsample=0.85; total time=16.3min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=12, min_child_weight=4, n_estimators=900, subsample=0.6; total time=16.4min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=12, min_child_weight=4, n_estimators=900, subsample=0.6; total time=16.4min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=12, min_child_weight=4, n_estimators=900, subsample=0.6; total time=16.0min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=12, min_child_weight=4, n_estimators=900, subsample=0.6; total time=16.0min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=12, min_child_weight=4, n_estimators=900, subsample=0.6; total time=16.0min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=13, min_child_weight=2, n_estimators=900, subsample=0.65; total time=33.3min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=13, min_child_weight=2, n_estimators=900, subsample=0.65; total time=33.4min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=13, min_child_weight=2, n_estimators=900, subsample=0.65; total time=33.3min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=13, min_child_weight=2, n_estimators=900, subsample=0.65; total time=33.4min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=13, min_child_weight=2, n_estimators=900, subsample=0.65; total time=33.3min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=15, min_child_weight=4, n_estimators=700, subsample=0.75; total time=18.3min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=15, min_child_weight=4, n_estimators=700, subsample=0.75; total time=33.4min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=15, min_child_weight=4, n_estimators=700, subsample=0.75; total time=33.4min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=15, min_child_weight=4, n_estimators=700, subsample=0.75; total time=16.2min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=15, min_child_weight=4, n_estimators=700, subsample=0.75; total time=16.2min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=15, min_child_weight=3, n_estimators=1000, subsample=0.65; total time=16.3min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=15, min_child_weight=3, n_estimators=1000, subsample=0.65; total time=16.3min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=15, min_child_weight=3, n_estimators=1000, subsample=0.65; total time=16.4min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=13, min_child_weight=4, n_estimators=800, subsample=0.75; total time=  45.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=13, min_child_weight=4, n_estimators=800, subsample=0.75; total time=  45.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=15, min_child_weight=3, n_estimators=1000, subsample=0.65; total time=16.2min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=15, min_child_weight=3, n_estimators=1000, subsample=0.65; total time= 1.2min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=13, min_child_weight=4, n_estimators=800, subsample=0.75; total time=  46.1s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.1, max_depth=12, min_child_weight=2, n_estimators=700, subsample=0.85; total time=  41.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=13, min_child_weight=4, n_estimators=800, subsample=0.75; total time=  47.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=13, min_child_weight=4, n_estimators=800, subsample=0.75; total time=  48.2s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.1, max_depth=12, min_child_weight=2, n_estimators=700, subsample=0.85; total time=  39.5s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.1, max_depth=12, min_child_weight=2, n_estimators=700, subsample=0.85; total time=  40.0s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.1, max_depth=12, min_child_weight=2, n_estimators=700, subsample=0.85; total time=  40.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.08, max_depth=8, min_child_weight=3, n_estimators=1000, subsample=0.75; total time=  34.6s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.1, max_depth=12, min_child_weight=2, n_estimators=700, subsample=0.85; total time=  40.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.08, max_depth=8, min_child_weight=3, n_estimators=1000, subsample=0.75; total time=  35.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.08, max_depth=8, min_child_weight=3, n_estimators=1000, subsample=0.75; total time=  35.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.08, max_depth=8, min_child_weight=3, n_estimators=1000, subsample=0.75; total time=  36.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.08, max_depth=8, min_child_weight=3, n_estimators=1000, subsample=0.75; total time=  34.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=12, min_child_weight=4, n_estimators=800, subsample=0.85; total time=  48.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=12, min_child_weight=4, n_estimators=800, subsample=0.85; total time=  47.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=12, min_child_weight=4, n_estimators=800, subsample=0.85; total time=  46.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=15, min_child_weight=2, n_estimators=1000, subsample=0.65; total time= 1.5min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=15, min_child_weight=2, n_estimators=1000, subsample=0.65; total time= 1.5min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=15, min_child_weight=2, n_estimators=1000, subsample=0.65; total time= 1.5min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=15, min_child_weight=2, n_estimators=1000, subsample=0.65; total time= 1.4min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=15, min_child_weight=2, n_estimators=1000, subsample=0.65; total time= 1.5min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=12, min_child_weight=4, n_estimators=800, subsample=0.85; total time=  47.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=12, min_child_weight=4, n_estimators=800, subsample=0.85; total time=  47.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.15, max_depth=8, min_child_weight=4, n_estimators=700, subsample=0.6; total time=  27.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.15, max_depth=8, min_child_weight=4, n_estimators=700, subsample=0.6; total time=  27.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.15, max_depth=8, min_child_weight=4, n_estimators=700, subsample=0.6; total time=  27.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, min_child_weight=3, n_estimators=900, subsample=0.6; total time= 1.3min\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.15, max_depth=8, min_child_weight=4, n_estimators=700, subsample=0.6; total time=  28.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, min_child_weight=3, n_estimators=900, subsample=0.6; total time= 1.3min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, min_child_weight=3, n_estimators=900, subsample=0.6; total time= 1.3min\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.15, max_depth=8, min_child_weight=4, n_estimators=700, subsample=0.6; total time=  26.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, min_child_weight=3, n_estimators=900, subsample=0.6; total time= 1.3min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, min_child_weight=3, n_estimators=900, subsample=0.6; total time= 1.3min\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.05, max_depth=9, min_child_weight=4, n_estimators=1000, subsample=0.85; total time=  39.1s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.05, max_depth=9, min_child_weight=4, n_estimators=1000, subsample=0.85; total time=  40.1s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.05, max_depth=9, min_child_weight=4, n_estimators=1000, subsample=0.85; total time=  39.8s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.01, max_depth=9, min_child_weight=2, n_estimators=700, subsample=0.85; total time=  39.9s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.05, max_depth=9, min_child_weight=4, n_estimators=1000, subsample=0.85; total time=  40.6s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.05, max_depth=9, min_child_weight=4, n_estimators=1000, subsample=0.85; total time=  40.7s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.01, max_depth=9, min_child_weight=2, n_estimators=700, subsample=0.85; total time=  40.0s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.01, max_depth=9, min_child_weight=2, n_estimators=700, subsample=0.85; total time=  39.8s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.01, max_depth=9, min_child_weight=2, n_estimators=700, subsample=0.85; total time=  39.4s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.01, max_depth=9, min_child_weight=2, n_estimators=700, subsample=0.85; total time=  39.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.08, max_depth=11, min_child_weight=4, n_estimators=700, subsample=0.65; total time=  35.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.08, max_depth=11, min_child_weight=4, n_estimators=700, subsample=0.65; total time=  35.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.08, max_depth=11, min_child_weight=4, n_estimators=700, subsample=0.65; total time=  35.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.08, max_depth=11, min_child_weight=4, n_estimators=700, subsample=0.65; total time=  35.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.08, max_depth=11, min_child_weight=4, n_estimators=700, subsample=0.65; total time=  34.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=8, min_child_weight=3, n_estimators=800, subsample=0.65; total time=  32.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=8, min_child_weight=3, n_estimators=800, subsample=0.65; total time=  32.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=8, min_child_weight=3, n_estimators=800, subsample=0.65; total time=  32.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=8, min_child_weight=3, n_estimators=800, subsample=0.65; total time=  43.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=8, min_child_weight=3, n_estimators=800, subsample=0.65; total time=  44.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, min_child_weight=2, n_estimators=1100, subsample=0.6; total time= 2.0min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=10, min_child_weight=3, n_estimators=900, subsample=0.6; total time= 1.2min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, min_child_weight=2, n_estimators=1100, subsample=0.6; total time= 2.2min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, min_child_weight=2, n_estimators=1100, subsample=0.6; total time= 2.2min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, min_child_weight=2, n_estimators=1100, subsample=0.6; total time= 2.4min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=15, min_child_weight=2, n_estimators=1100, subsample=0.6; total time= 2.7min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=10, min_child_weight=3, n_estimators=900, subsample=0.6; total time= 1.7min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=10, min_child_weight=3, n_estimators=900, subsample=0.6; total time= 1.7min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=10, min_child_weight=3, n_estimators=900, subsample=0.6; total time= 1.6min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=10, min_child_weight=3, n_estimators=900, subsample=0.6; total time= 1.5min\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.08, max_depth=6, min_child_weight=2, n_estimators=1100, subsample=0.7; total time=  45.9s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.08, max_depth=6, min_child_weight=2, n_estimators=1100, subsample=0.7; total time=  46.7s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.08, max_depth=6, min_child_weight=2, n_estimators=1100, subsample=0.7; total time=  46.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=15, min_child_weight=2, n_estimators=900, subsample=0.6; total time= 2.4min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=15, min_child_weight=2, n_estimators=900, subsample=0.6; total time= 2.2min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=15, min_child_weight=2, n_estimators=900, subsample=0.6; total time= 2.1min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=15, min_child_weight=2, n_estimators=900, subsample=0.6; total time= 1.8min\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.08, max_depth=6, min_child_weight=2, n_estimators=1100, subsample=0.7; total time=  48.6s\n",
      "[CV] END colsample_bytree=0.75, learning_rate=0.08, max_depth=6, min_child_weight=2, n_estimators=1100, subsample=0.7; total time=  48.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=15, min_child_weight=2, n_estimators=900, subsample=0.6; total time= 1.8min\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=11, min_child_weight=3, n_estimators=800, subsample=0.6; total time= 1.2min\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=11, min_child_weight=3, n_estimators=800, subsample=0.6; total time= 1.2min\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.2, max_depth=13, min_child_weight=3, n_estimators=1100, subsample=0.7; total time= 1.9min\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=11, min_child_weight=3, n_estimators=800, subsample=0.6; total time= 1.1min\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.2, max_depth=13, min_child_weight=3, n_estimators=1100, subsample=0.7; total time= 1.8min\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.2, max_depth=13, min_child_weight=3, n_estimators=1100, subsample=0.7; total time= 1.9min\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.2, max_depth=13, min_child_weight=3, n_estimators=1100, subsample=0.7; total time= 1.8min\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.2, max_depth=13, min_child_weight=3, n_estimators=1100, subsample=0.7; total time= 1.9min\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.15, max_depth=10, min_child_weight=3, n_estimators=700, subsample=0.85; total time=  53.0s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.15, max_depth=10, min_child_weight=3, n_estimators=700, subsample=0.85; total time=  52.9s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.15, max_depth=10, min_child_weight=3, n_estimators=700, subsample=0.85; total time=  52.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=11, min_child_weight=3, n_estimators=800, subsample=0.6; total time= 1.1min\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.15, max_depth=10, min_child_weight=3, n_estimators=700, subsample=0.85; total time=  53.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=11, min_child_weight=3, n_estimators=800, subsample=0.6; total time= 1.1min\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.15, max_depth=10, min_child_weight=3, n_estimators=700, subsample=0.85; total time=  52.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, min_child_weight=3, n_estimators=1200, subsample=0.85; total time= 1.0min\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, min_child_weight=3, n_estimators=1200, subsample=0.85; total time= 1.0min\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, min_child_weight=3, n_estimators=1200, subsample=0.85; total time= 1.0min\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, min_child_weight=3, n_estimators=1200, subsample=0.85; total time= 1.0min\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=6, min_child_weight=3, n_estimators=1200, subsample=0.85; total time= 1.0min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.08, max_depth=11, min_child_weight=3, n_estimators=800, subsample=0.85; total time= 8.4min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.08, max_depth=11, min_child_weight=3, n_estimators=800, subsample=0.85; total time= 8.4min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.08, max_depth=11, min_child_weight=3, n_estimators=800, subsample=0.85; total time= 8.4min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=14, min_child_weight=2, n_estimators=1200, subsample=0.85; total time= 9.7min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=14, min_child_weight=2, n_estimators=1200, subsample=0.85; total time= 9.7min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=14, min_child_weight=2, n_estimators=1200, subsample=0.85; total time= 9.7min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=14, min_child_weight=2, n_estimators=1200, subsample=0.85; total time= 9.5min\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.08, max_depth=11, min_child_weight=3, n_estimators=800, subsample=0.85; total time=  42.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.08, max_depth=11, min_child_weight=3, n_estimators=800, subsample=0.85; total time=  36.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=14, min_child_weight=2, n_estimators=1200, subsample=0.85; total time= 9.3min\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.2, max_depth=12, min_child_weight=3, n_estimators=1100, subsample=0.75; total time= 1.1min\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.2, max_depth=12, min_child_weight=3, n_estimators=1100, subsample=0.75; total time= 1.0min\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.2, max_depth=12, min_child_weight=3, n_estimators=1100, subsample=0.75; total time= 1.0min\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.2, max_depth=12, min_child_weight=3, n_estimators=1100, subsample=0.75; total time= 1.1min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=10, min_child_weight=2, n_estimators=1200, subsample=0.6; total time=  56.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=10, min_child_weight=2, n_estimators=1200, subsample=0.6; total time=  55.6s\n",
      "[CV] END colsample_bytree=0.85, learning_rate=0.2, max_depth=12, min_child_weight=3, n_estimators=1100, subsample=0.75; total time= 1.1min\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=10, min_child_weight=2, n_estimators=1200, subsample=0.6; total time=  57.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=4, n_estimators=800, subsample=0.75; total time=  33.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=4, n_estimators=800, subsample=0.75; total time=  33.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=10, min_child_weight=2, n_estimators=1200, subsample=0.6; total time=  56.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=4, n_estimators=800, subsample=0.75; total time=  33.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=4, n_estimators=800, subsample=0.75; total time=  33.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=7, min_child_weight=4, n_estimators=800, subsample=0.75; total time=  33.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=10, min_child_weight=2, n_estimators=1200, subsample=0.6; total time=  56.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=9, min_child_weight=2, n_estimators=1200, subsample=0.75; total time=  49.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=9, min_child_weight=2, n_estimators=1200, subsample=0.75; total time=  46.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=9, min_child_weight=2, n_estimators=1200, subsample=0.75; total time=  45.0s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=9, min_child_weight=2, n_estimators=1200, subsample=0.75; total time=  41.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=9, min_child_weight=2, n_estimators=1200, subsample=0.75; total time=  40.9s\n"
     ]
    }
   ],
   "source": [
    "random_search.fit(X_train, y_train)\n",
    "best_params = random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.65,\n",
       " 'n_estimators': 900,\n",
       " 'min_child_weight': 2,\n",
       " 'max_depth': 13,\n",
       " 'learning_rate': 0.01,\n",
       " 'colsample_bytree': 0.7}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb = xgb.XGBRegressor(**best_params, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 11254.77302469131 (0.0) Mean MSE: 779091871.6550146\n"
     ]
    }
   ],
   "source": [
    "scores_mae = cross_val_score(best_xgb, X_train, y_train, scoring='neg_mean_absolute_error', cv=5, n_jobs=-1)\n",
    "scores_mse = cross_val_score(best_xgb, X_train, y_train, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "scores_mae = abs(scores_mae)\n",
    "scores_mae = scores_mae.mean()\n",
    "scores_std = scores_mae.std()\n",
    "scores_mse = abs(scores_mse)\n",
    "scores_mse = scores_mse.mean()\n",
    "print(f'Mean MAE: {scores_mae} ({scores_std}) Mean MSE: {scores_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.7, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=13, max_leaves=None,\n",
       "             min_child_weight=2, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=900, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=123, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.7, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=13, max_leaves=None,\n",
       "             min_child_weight=2, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=900, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=123, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.7, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=13, max_leaves=None,\n",
       "             min_child_weight=2, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=900, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=123, ...)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"XGBoost Model Predictions vs. Actual Values\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # Line of perfect prediction\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Split using median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.0 Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_low = df[df['price'] <= 53000]\n",
    "df_high = df[df['price'] > 53000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split df_high and df_low into features (X) and target (y)\n",
    "X_high, y_high = df_high.drop(columns=['price']), df_high['price']\n",
    "X_low, y_low = df_low.drop(columns=['price']), df_low['price']\n",
    "\n",
    "# Train-test split for df_high\n",
    "X_high_train, X_high_test, y_high_train, y_high_test = train_test_split(X_high, y_high, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train-test split for df_low\n",
    "X_low_train, X_low_test, y_low_train, y_low_test = train_test_split(X_low, y_low, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Estimate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1.1 High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBR = xgb.XGBRegressor(n_estimators=1000, max_depth=7, eta=0.1, subsample=0.7, colsample_bytree=0.8)\n",
    "\n",
    "# # Define the parameter grid\n",
    "# param_grid = {\n",
    "#     'n_estimators': [700, 800, 900, 1000, 1100, 1200],\n",
    "#     'max_depth': [6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "#     'learning_rate': [0.01, 0.05, 0.08, 0.1, 0.15, 0.2],\n",
    "#     'subsample': [0.6, 0.65, 0.7, 0.75, 0.8, 0.85],\n",
    "#     'colsample_bytree': [0.7, 0.75, 0.8, 0.85, 0.9],\n",
    "#     'min_child_weight': [2, 3, 4]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zuzanna/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=0.8, device=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False, eta=0.1,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learnin...\n",
       "                                          n_estimators=1000, n_jobs=None,\n",
       "                                          num_parallel_tree=None, ...),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.7, 0.75, 0.8,\n",
       "                                                             0.85, 0.9],\n",
       "                                        &#x27;learning_rate&#x27;: [0.01, 0.05, 0.08, 0.1,\n",
       "                                                          0.15, 0.2],\n",
       "                                        &#x27;max_depth&#x27;: [6, 7, 8, 9, 10, 11, 12,\n",
       "                                                      13, 14, 15],\n",
       "                                        &#x27;min_child_weight&#x27;: [2, 3, 4],\n",
       "                                        &#x27;n_estimators&#x27;: [700, 800, 900, 1000,\n",
       "                                                         1100, 1200],\n",
       "                                        &#x27;subsample&#x27;: [0.6, 0.65, 0.7, 0.75, 0.8,\n",
       "                                                      0.85]},\n",
       "                   random_state=42, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=0.8, device=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False, eta=0.1,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learnin...\n",
       "                                          n_estimators=1000, n_jobs=None,\n",
       "                                          num_parallel_tree=None, ...),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.7, 0.75, 0.8,\n",
       "                                                             0.85, 0.9],\n",
       "                                        &#x27;learning_rate&#x27;: [0.01, 0.05, 0.08, 0.1,\n",
       "                                                          0.15, 0.2],\n",
       "                                        &#x27;max_depth&#x27;: [6, 7, 8, 9, 10, 11, 12,\n",
       "                                                      13, 14, 15],\n",
       "                                        &#x27;min_child_weight&#x27;: [2, 3, 4],\n",
       "                                        &#x27;n_estimators&#x27;: [700, 800, 900, 1000,\n",
       "                                                         1100, 1200],\n",
       "                                        &#x27;subsample&#x27;: [0.6, 0.65, 0.7, 0.75, 0.8,\n",
       "                                                      0.85]},\n",
       "                   random_state=42, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eta=0.1, eval_metric=None,\n",
       "             feature_types=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eta=0.1, eval_metric=None,\n",
       "             feature_types=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=0.8, device=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False, eta=0.1,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learnin...\n",
       "                                          n_estimators=1000, n_jobs=None,\n",
       "                                          num_parallel_tree=None, ...),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.7, 0.75, 0.8,\n",
       "                                                             0.85, 0.9],\n",
       "                                        'learning_rate': [0.01, 0.05, 0.08, 0.1,\n",
       "                                                          0.15, 0.2],\n",
       "                                        'max_depth': [6, 7, 8, 9, 10, 11, 12,\n",
       "                                                      13, 14, 15],\n",
       "                                        'min_child_weight': [2, 3, 4],\n",
       "                                        'n_estimators': [700, 800, 900, 1000,\n",
       "                                                         1100, 1200],\n",
       "                                        'subsample': [0.6, 0.65, 0.7, 0.75, 0.8,\n",
       "                                                      0.85]},\n",
       "                   random_state=42, verbose=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomizedSearchCV for df_high\n",
    "random_search_high = RandomizedSearchCV(XGBR, param_distributions=param_grid, n_iter=50, cv=5, n_jobs=-1, verbose=1, random_state=42)\n",
    "random_search_high.fit(X_high_train, y_high_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.75,\n",
       " 'n_estimators': 700,\n",
       " 'min_child_weight': 4,\n",
       " 'max_depth': 15,\n",
       " 'learning_rate': 0.01,\n",
       " 'colsample_bytree': 0.9}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best parameters for df_high\n",
    "best_params_high = random_search_high.best_params_\n",
    "best_params_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=15, max_leaves=None,\n",
       "             min_child_weight=4, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=700, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=15, max_leaves=None,\n",
       "             min_child_weight=4, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=700, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=15, max_leaves=None,\n",
       "             min_child_weight=4, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=700, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the best model for df_high\n",
    "best_xgb_high = xgb.XGBRegressor(**best_params_high, objective='reg:squarederror')\n",
    "best_xgb_high.fit(X_high_train, y_high_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate for df_high\n",
    "y_high_pred = best_xgb_high.predict(X_high_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 15927.495373375452 (94.77010481716525) Mean MSE: 1408900073.082095\n"
     ]
    }
   ],
   "source": [
    "scores_mae = cross_val_score(best_xgb_high, X_high_train, y_high_train, scoring='neg_mean_absolute_error', cv=5, n_jobs=-1)\n",
    "scores_mse = cross_val_score(best_xgb_high, X_high_train, y_high_train, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "scores_mae = abs(scores_mae)\n",
    "scores_mae_high = scores_mae.mean()\n",
    "scores_std_high = scores_mae.std()\n",
    "scores_mse = abs(scores_mse)\n",
    "scores_mse_high = scores_mse.mean()\n",
    "print(f'Mean MAE: {scores_mae_high} ({scores_std_high}) Mean MSE: {scores_mse_high}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1.2 Low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=0.8, device=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False, eta=0.1,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learnin...\n",
       "                                          n_estimators=1000, n_jobs=None,\n",
       "                                          num_parallel_tree=None, ...),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.7, 0.75, 0.8,\n",
       "                                                             0.85, 0.9],\n",
       "                                        &#x27;learning_rate&#x27;: [0.01, 0.05, 0.08, 0.1,\n",
       "                                                          0.15, 0.2],\n",
       "                                        &#x27;max_depth&#x27;: [6, 7, 8, 9, 10, 11, 12,\n",
       "                                                      13, 14, 15],\n",
       "                                        &#x27;min_child_weight&#x27;: [2, 3, 4],\n",
       "                                        &#x27;n_estimators&#x27;: [700, 800, 900, 1000,\n",
       "                                                         1100, 1200],\n",
       "                                        &#x27;subsample&#x27;: [0.6, 0.65, 0.7, 0.75, 0.8,\n",
       "                                                      0.85]},\n",
       "                   random_state=42, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=0.8, device=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False, eta=0.1,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learnin...\n",
       "                                          n_estimators=1000, n_jobs=None,\n",
       "                                          num_parallel_tree=None, ...),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.7, 0.75, 0.8,\n",
       "                                                             0.85, 0.9],\n",
       "                                        &#x27;learning_rate&#x27;: [0.01, 0.05, 0.08, 0.1,\n",
       "                                                          0.15, 0.2],\n",
       "                                        &#x27;max_depth&#x27;: [6, 7, 8, 9, 10, 11, 12,\n",
       "                                                      13, 14, 15],\n",
       "                                        &#x27;min_child_weight&#x27;: [2, 3, 4],\n",
       "                                        &#x27;n_estimators&#x27;: [700, 800, 900, 1000,\n",
       "                                                         1100, 1200],\n",
       "                                        &#x27;subsample&#x27;: [0.6, 0.65, 0.7, 0.75, 0.8,\n",
       "                                                      0.85]},\n",
       "                   random_state=42, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eta=0.1, eval_metric=None,\n",
       "             feature_types=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eta=0.1, eval_metric=None,\n",
       "             feature_types=None, gamma=None, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
       "             n_jobs=None, num_parallel_tree=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=0.8, device=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False, eta=0.1,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learnin...\n",
       "                                          n_estimators=1000, n_jobs=None,\n",
       "                                          num_parallel_tree=None, ...),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.7, 0.75, 0.8,\n",
       "                                                             0.85, 0.9],\n",
       "                                        'learning_rate': [0.01, 0.05, 0.08, 0.1,\n",
       "                                                          0.15, 0.2],\n",
       "                                        'max_depth': [6, 7, 8, 9, 10, 11, 12,\n",
       "                                                      13, 14, 15],\n",
       "                                        'min_child_weight': [2, 3, 4],\n",
       "                                        'n_estimators': [700, 800, 900, 1000,\n",
       "                                                         1100, 1200],\n",
       "                                        'subsample': [0.6, 0.65, 0.7, 0.75, 0.8,\n",
       "                                                      0.85]},\n",
       "                   random_state=42, verbose=1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomizedSearchCV for low\n",
    "random_search_low = RandomizedSearchCV(XGBR, param_distributions=param_grid, n_iter=50, cv=5, n_jobs=-1, verbose=1, random_state=42)\n",
    "random_search_low.fit(X_low_train, y_low_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.85,\n",
       " 'n_estimators': 1100,\n",
       " 'min_child_weight': 3,\n",
       " 'max_depth': 11,\n",
       " 'learning_rate': 0.05,\n",
       " 'colsample_bytree': 0.7}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best parameters for df_low\n",
    "best_params_low = random_search_low.best_params_\n",
    "best_params_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.7, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=11, max_leaves=None,\n",
       "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=1100, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.7, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=11, max_leaves=None,\n",
       "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=1100, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.7, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=11, max_leaves=None,\n",
       "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=1100, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the best model for df_high\n",
    "best_xgb_low = xgb.XGBRegressor(**best_params_low, objective='reg:squarederror')\n",
    "best_xgb_low.fit(X_low_train, y_low_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 3654.3696118850944 (11.960029876812547) Mean MSE: 29621948.10847801\n"
     ]
    }
   ],
   "source": [
    "scores_mae = cross_val_score(best_xgb_low, X_low_train, y_low_train, scoring='neg_mean_absolute_error', cv=5, n_jobs=-1)\n",
    "scores_mse = cross_val_score(best_xgb_low, X_low_train, y_low_train, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "scores_mae = abs(scores_mae)\n",
    "scores_mae_low = scores_mae.mean()\n",
    "scores_std_low= scores_mae.std()\n",
    "scores_mse = abs(scores_mse)\n",
    "scores_mse_low = scores_mse.mean()\n",
    "print(f'Mean MAE: {scores_mae_low} ({scores_std_low}) Mean MSE: {scores_mse_low}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge low + high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb_low = xgb.XGBRegressor(**best_params_low, random_state=123)\n",
    "best_xgb_low.fit(X_low_train, y_low_train)\n",
    "low_pred_y = best_xgb_low.predict(X_low_test)\n",
    "\n",
    "best_xgb_high = xgb.XGBRegressor(**best_params_high, random_state=123)\n",
    "best_xgb_high.fit(X_high_train, y_high_train)\n",
    "high_pred_y = best_xgb_high.predict(X_high_test)\n",
    "\n",
    "low_true_pred = pd.DataFrame({'True': y_low_test, 'Predicted': low_pred_y})\n",
    "high_true_pred = pd.DataFrame({'True': y_high_test, 'Predicted': high_pred_y})\n",
    "\n",
    "low_high_true_pred = pd.concat([low_true_pred, high_true_pred])\n",
    "\n",
    "true_values = low_high_true_pred['True']\n",
    "estimated_values = low_high_true_pred['Predicted']\n",
    "scores_mae_low_high = np.mean(np.abs(true_values - estimated_values))\n",
    "scores_mse_low_high = np.mean((true_values - estimated_values) ** 2)\n",
    "scores_std_low_high = np.std(np.abs(true_values - estimated_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>splitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>11254.773025</td>\n",
       "      <td>9169.194378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mse</th>\n",
       "      <td>779091871.655015</td>\n",
       "      <td>515309944.823920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sd. error</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>20766.218223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       all         splitted\n",
       "mae           11254.773025      9169.194378\n",
       "mse       779091871.655015 515309944.823920\n",
       "sd. error         0.000000     20766.218223"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance = pd.DataFrame({\n",
    "    'all': [scores_mae, scores_mse],\n",
    "    'splitted': [scores_mae_low_high, scores_mse_low_high]\n",
    "})\n",
    "performance.index = ['mae', 'mse']\n",
    "pd.options.display.float_format = '{:.6f}'.format\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparision table shows that we benefit for splitting the data for cars below the medium price and above. Further extensions of the model may include other splitting points, which would improve the precision of predicitons even more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
